{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 2\n"
     ]
    }
   ],
   "source": [
    "import re, string\n",
    "import csv\n",
    "from datetime import datetime\n",
    "text_file = sc.textFile('lab5data/*.tess')\n",
    "\n",
    "#text_file = sc.textFile('lab5data/latin/*.tess') \n",
    "#complete latin text to test, long runtime need\n",
    "print(\"Number of partitions: {}\".format(text_file.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latin = {};\n",
    "with open('new_lemmatizer.csv') as csvfile:\n",
    "     spamreader = csv.reader(csvfile, delimiter=',')\n",
    "     for row in spamreader:\n",
    "         latin[row[1]] = row[0]\n",
    "# save the latin data as map data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<ambrose. ap_david_altera. 1> Fortasse plerosque psalmi titulus offenderit, quem audistis legi, quod uenit ad eum Nathan propheta, cum intrauit ad Betsabee. simul etiam non mediocre scrupulum mouere potuit inperitis euangelii lectio, quae decursa est, in quo aduertistis adulteram Christo oblatam eandemque sine damnatione dimissam. nam profecto si quis ea auribus accipiat otiosis, incentiuum erroris incurrit, cum legit sancti uiri adulterium et adulterae absolutionem, humano propemodum diuinoque lapsus exemplo, quod et homo putauerit adulterium esse faciendum et deus censuerit adulterium non esse damnandum. lubrica igitur ad lapsum uia uel ueniae uel concupiscentiae.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string.punctuation;\n",
    "punc = '!\"#$%&\\'()*+,./:;=?@[\\\\]^_`{|}~' # let <> became the exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fallowing function is for 3-gram##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(x):\n",
    "    cvsSplitBy = '>';\n",
    "    transtable = {ord(c): None for c in punc}\n",
    "    temp = x.translate(transtable);\n",
    "    spliter = [];\n",
    "    spliter = temp.split(cvsSplitBy);\n",
    "    if len(spliter)!=1:\n",
    "        cleaned_text = spliter[1];\n",
    "    else:\n",
    "        cleaned_text = \"\";\n",
    "    cleaned_data = cleaned_text.split(' ');\n",
    "    converted = \"\";\n",
    "    i = 0;\n",
    "    j = 0;\n",
    "    d = 0;\n",
    "    for i in range(0,len(cleaned_data)):\n",
    "        j = i;\n",
    "        for j in range(i+1,len(cleaned_data)):\n",
    "#             if len(cleaned_data[i])!=0 and len(cleaned_data[j])!=0:\n",
    "#                      converted = converted+cleaned_data[i]+','+cleaned_data[j]+str(spliter[0])+'>'+'@';\n",
    "            d = j;\n",
    "            for d in range(j+1,len(cleaned_data)):\n",
    "                cur = sorted([cleaned_data[i],cleaned_data[j],cleaned_data[d]]);\n",
    "                if cur[0] in latin:\n",
    "                    cur[0] = latin[cur[0]];\n",
    "                if cur[1] in latin:\n",
    "                    cur[1] = latin[cur[1]];\n",
    "                if cur[2] in latin:\n",
    "                    cur[2] = latin[cur[2]];    \n",
    "                if len(cleaned_data[i])!=0 and len(cleaned_data[j])!=0 and len(cleaned_data[d])!=0:\n",
    "                    converted = converted+cur[0]+','+cur[1]+','+cur[2]+str(spliter[0])+'>'+'@';\n",
    "    lowercased_str = converted.lower()\n",
    "    return lowercased_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start=datetime.now()\n",
    "one_RDD = text_file.flatMap(lambda x: clean_str(x).split('@'))\n",
    "one_RDD = one_RDD.map(lambda x: (x[:x.find('<')],x[x.find('<'):]))\n",
    "one_RDD = one_RDD.reduceByKey(lambda x,y: x + y)\n",
    "one_RDD.saveAsTextFile('TextOutput_1')\n",
    "print (datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fallowing function is for 2-gram#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str_1(x):\n",
    "    cvsSplitBy = '>';\n",
    "    transtable = {ord(c): None for c in punc}\n",
    "    temp = x.translate(transtable);\n",
    "    spliter = [];\n",
    "    spliter = temp.split(cvsSplitBy);\n",
    "    if len(spliter)!=1:\n",
    "        cleaned_text = spliter[1];\n",
    "    else:\n",
    "        cleaned_text = \"\";\n",
    "    cleaned_data = cleaned_text.split(' ');\n",
    "    converted = \"\";\n",
    "    i = 0;\n",
    "    j = 0;\n",
    "    d = 0;\n",
    "    for i in range(0,len(cleaned_data)):\n",
    "        j = i;\n",
    "        for j in range(i+1,len(cleaned_data)):\n",
    "            cur = sorted([cleaned_data[i],cleaned_data[j]]);\n",
    "            if cur[0] in latin:\n",
    "                cur[0] = latin[cur[0]];\n",
    "            if cur[1] in latin:\n",
    "                cur[1] = latin[cur[1]];\n",
    "            if len(cleaned_data[i])!=0 and len(cleaned_data[j])!=0:\n",
    "                     converted = converted+cur[0]+','+cur[1]+str(spliter[0])+'>'+'@';\n",
    "                     \n",
    "\n",
    "    lowercased_str = converted.lower()\n",
    "    return lowercased_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.834302\n"
     ]
    }
   ],
   "source": [
    "start=datetime.now()\n",
    "two_RDD = text_file.flatMap(lambda x: clean_str_1(x).split('@'))\n",
    "two_RDD = two_RDD.map(lambda x: (x[:x.find('<')],x[x.find('<'):]))\n",
    "two_RDD = two_RDD.reduceByKey(lambda x,y: x + y)\n",
    "two_RDD.saveAsTextFile('TextOutput')\n",
    "print (datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Output#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('', ''),\n",
       " ('erroris,hu虂manas,quo', '<ambrose apdavidaltera 1>'),\n",
       " ('exemploque,lubrica,si虂ne', '<ambrose apdavidaltera 1>'),\n",
       " ('erroris,intrauit,quem', '<ambrose apdavidaltera 1>'),\n",
       " ('otiosis,putauerit,uenit', '<ambrose apdavidaltera 1>')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of partitions: {}\".format(one_RDD.getNumPartitions()))\n",
    "one_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of partitions: {}\".format(two_RDD.getNumPartitions()))\n",
    "two_RDD.take(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
